#!/usr/bin/env python
# -*- coding: utf-8 -*-
import sys
import logging
from datetime import datetime, timedelta
from pyspark.sql import SparkSession

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


def main():
    try:
        # Initialize Spark session
        spark = SparkSession.builder \
            .appName("Online_Model_Medium_Term_Weekly") \
            .config("spark.sql.caseSensitive", "false") \
            .config("hive.exec.dynamic.partition", "true") \
            .config("hive.exec.dynamic.partition.mode", "nonstrict") \
            .config("spark.sql.sources.partitionOverwriteMode", "dynamic") \
            .enableHiveSupport() \
            .getOrCreate()

        # Determine run date
        if len(sys.argv) == 1:
            run_date_dt = datetime.now().date()
        elif len(sys.argv) == 2:
            try:
                run_date_dt = datetime.strptime(sys.argv[1], '%Y-%m-%d').date()
            except ValueError:
                logger.error("Invalid date format. Use YYYY-MM-DD.")
                spark.stop()
                sys.exit(1)
        else:
            logger.error("Usage: python combined_query_weekly.py [YYYY-MM-DD]")
            spark.stop()
            sys.exit(1)

        # Medium-term window: last 7 days
        mt_from_date_dt = run_date_dt - timedelta(days=6)
        mt_from_date = mt_from_date_dt.strftime('%Y-%m-%d')
        mt_to_date = run_date_dt.strftime('%Y-%m-%d')

        run_type = "default" if len(sys.argv) == 1 else "recovery"
        target_table = "hive.analytics_prod.oim_medium_term_raw"

        logger.info("Starting %s medium-term job for %s â†’ %s", run_type, mt_from_date, mt_to_date)

        # Base query combining all interaction sources
        query = """
            SELECT
                subscription_id,
                app_name,
                lower(app_category) AS app_category,
                sum(cast(mbs AS decimal(18,6))) AS total_mbs,
                cast(sum(no_of_sessions) AS INT) AS total_sessions,
                COUNT(DISTINCT day) AS access_days,
                'app' AS type,
                '{to_date}' AS day
            FROM hive.analytics_prod.online_interest_protocols_daily
            WHERE day BETWEEN '{from_date}' AND '{to_date}'
            GROUP BY subscription_id, app_name, app_category

            UNION ALL

            SELECT
                subscription_id,
                app_name,
                lower(app_category) AS app_category,
                0 AS total_mbs,
                sum(no_of_sessions) AS total_sessions,
                COUNT(DISTINCT day) AS access_days,
                'url' AS type,
                '{to_date}' AS day
            FROM hive.analytics_prod.online_interest_urls_daily
            WHERE day BETWEEN '{from_date}' AND '{to_date}'
            GROUP BY subscription_id, app_name, app_category

            UNION ALL

            SELECT
                subscription_id,
                app_name,
                lower(app_category) AS app_category,
                0 AS total_mbs,
                sum(no_of_sessions) AS total_sessions,
                COUNT(DISTINCT day) AS access_days,
                'sms' AS type,
                '{to_date}' AS day
            FROM hive.analytics_prod.online_interest_sms_daily
            WHERE day BETWEEN '{from_date}' AND '{to_date}'
            GROUP BY subscription_id, app_name, app_category

            UNION ALL

            SELECT
                subscription_id,
                app_name,
                lower(app_category) AS app_category,
                0 AS total_mbs,
                sum(no_of_sessions) AS total_sessions,
                COUNT(DISTINCT day) AS access_days,
                'og' AS type,
                '{to_date}' AS day
